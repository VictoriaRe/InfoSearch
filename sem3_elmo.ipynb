{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled4.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2IL6xP83t9fQ",
        "colab_type": "text"
      },
      "source": [
        "# ELMO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kWIHvCuQuB14",
        "colab_type": "text"
      },
      "source": [
        "# (1) Скачиваем ELMO"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J585Vl5Rt_EV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "58126091-32bc-4733-a66d-b10634c0f3a4"
      },
      "source": [
        "!wget \"http://vectors.nlpl.eu/repository/11/196.zip\""
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-10-23 20:42:06--  http://vectors.nlpl.eu/repository/11/196.zip\n",
            "Resolving vectors.nlpl.eu (vectors.nlpl.eu)... 129.240.189.225\n",
            "Connecting to vectors.nlpl.eu (vectors.nlpl.eu)|129.240.189.225|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 206986345 (197M) [application/zip]\n",
            "Saving to: ‘196.zip’\n",
            "\n",
            "196.zip             100%[===================>] 197.40M  64.1MB/s    in 3.2s    \n",
            "\n",
            "2019-10-23 20:42:14 (61.1 MB/s) - ‘196.zip’ saved [206986345/206986345]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i0aXerpSuEJW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 148
        },
        "outputId": "3c0f5cc6-5513-4a70-b758-0d2da3aa1fdd"
      },
      "source": [
        "!unzip '196.zip' -d 'ELMO'"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  196.zip\n",
            "  inflating: ELMO/meta.json          \n",
            "  inflating: ELMO/model.hdf5         \n",
            "  inflating: ELMO/options.json       \n",
            "  inflating: ELMO/README             \n",
            "  inflating: ELMO/vocab.txt          \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W0AAMxl6uIZ2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "os.mkdir('bilm')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xNIZ6FhquQo5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        },
        "outputId": "38b6cd69-4d32-46ae-d247-dcf434b25bfe"
      },
      "source": [
        "! pip install bilm"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting bilm\n",
            "  Downloading https://files.pythonhosted.org/packages/22/a6/711e6ea5a05f7ce72f0a5c6c3bfbd1451aeb8810c9ec8074d5667e3ff433/bilm-0.1.post5-py3-none-any.whl\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from bilm) (2.8.0)\n",
            "Requirement already satisfied: numpy>=1.7 in /usr/local/lib/python3.6/dist-packages (from h5py->bilm) (1.16.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from h5py->bilm) (1.12.0)\n",
            "Installing collected packages: bilm\n",
            "Successfully installed bilm-0.1.post5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4sZqkmAQuKLA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%load_ext autoreload\n",
        "\n",
        "import time\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from elmo_helpers import tokenize, get_elmo_vectors, load_elmo_embeddings\n",
        "\n",
        "tf.reset_default_graph()\n",
        "elmo_path = 'ELMO'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DvrpH2VcuLo-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 598
        },
        "outputId": "f887cb4f-60e8-4b35-9ea8-61ce5381f064"
      },
      "source": [
        "batcher, sentence_character_ids, elmo_sentence_input = load_elmo_embeddings(elmo_path)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /content/elmo_helpers.py:56: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/bilm/model.py:276: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/bilm/model.py:333: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/bilm/model.py:378: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/bilm/model.py:522: LSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This class is equivalent as tf.keras.layers.LSTMCell, and will be replaced by that in Tensorflow 2.0.\n",
            "WARNING:tensorflow:From /content/bilm/model.py:566: The name tf.nn.rnn_cell.LSTMStateTuple is deprecated. Please use tf.compat.v1.nn.rnn_cell.LSTMStateTuple instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/bilm/model.py:567: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/rnn_cell_impl.py:958: Layer.add_variable (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.add_weight` method instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/rnn_cell_impl.py:962: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/rnn.py:244: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /content/bilm/model.py:591: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/bilm/model.py:536: The name tf.nn.rnn_cell.ResidualWrapper is deprecated. Please use tf.compat.v1.nn.rnn_cell.ResidualWrapper instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/bilm/elmo.py:92: The name tf.get_collection is deprecated. Please use tf.compat.v1.get_collection instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/bilm/elmo.py:93: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i1yYwqKm1msE",
        "colab_type": "text"
      },
      "source": [
        "# (2) Скачиваем корпус\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dkIYQYZY1s2E",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 438
        },
        "outputId": "94de83f6-1f53-46eb-a535-7bf9bea35852"
      },
      "source": [
        "!wget 'https://www.dropbox.com/s/jaa5y82qzul6byn/quora_question_pairs_rus.csv'"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-10-23 20:45:46--  https://www.dropbox.com/s/jaa5y82qzul6byn/quora_question_pairs_rus.csv\n",
            "Resolving www.dropbox.com (www.dropbox.com)... 162.125.65.1, 2620:100:6021:1::a27d:4101\n",
            "Connecting to www.dropbox.com (www.dropbox.com)|162.125.65.1|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: /s/raw/jaa5y82qzul6byn/quora_question_pairs_rus.csv [following]\n",
            "--2019-10-23 20:45:46--  https://www.dropbox.com/s/raw/jaa5y82qzul6byn/quora_question_pairs_rus.csv\n",
            "Reusing existing connection to www.dropbox.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://uc992ace9b14419fdf1366c169e2.dl.dropboxusercontent.com/cd/0/inline/Aq_2oP13JyZE_Q9dxN7Umlo1FxUTWq1-thO45_5cMf9sWNlzJXqby-uuQ_y6MBMB26teYi_-h1SldrlrSpimkvQz26SBa3ldoHPCflvGtbHjzjv0JWyCYpAdWX0sWo_VwMc/file# [following]\n",
            "--2019-10-23 20:45:46--  https://uc992ace9b14419fdf1366c169e2.dl.dropboxusercontent.com/cd/0/inline/Aq_2oP13JyZE_Q9dxN7Umlo1FxUTWq1-thO45_5cMf9sWNlzJXqby-uuQ_y6MBMB26teYi_-h1SldrlrSpimkvQz26SBa3ldoHPCflvGtbHjzjv0JWyCYpAdWX0sWo_VwMc/file\n",
            "Resolving uc992ace9b14419fdf1366c169e2.dl.dropboxusercontent.com (uc992ace9b14419fdf1366c169e2.dl.dropboxusercontent.com)... 162.125.65.6, 2620:100:6021:6::a27d:4106\n",
            "Connecting to uc992ace9b14419fdf1366c169e2.dl.dropboxusercontent.com (uc992ace9b14419fdf1366c169e2.dl.dropboxusercontent.com)|162.125.65.6|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 94499321 (90M) [text/plain]\n",
            "Saving to: ‘quora_question_pairs_rus.csv’\n",
            "\n",
            "quora_question_pair 100%[===================>]  90.12M  43.4MB/s    in 2.1s    \n",
            "\n",
            "2019-10-23 20:45:49 (43.4 MB/s) - ‘quora_question_pairs_rus.csv’ saved [94499321/94499321]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1dmpvzNj1Idk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "corpus = 'quora_question_pairs_rus.csv'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vwqo0mDn2FJ1",
        "colab_type": "text"
      },
      "source": [
        "# Индексируем корпус\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HICGta0v1TDm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import csv\n",
        "\n",
        "def get_data_elmo(corpus, stop=5000):\n",
        "    \"\"\"\n",
        "    Проходит по корпусу и токенизирует тексты.\n",
        "\n",
        "    :param corpus: path to csv file with corpus\n",
        "    :param stop: int, how many lines we want to get\n",
        "    :return: \n",
        "        indexed -> list of list of strings\n",
        "        id_to_text -> dict, map of text_id to raw text. \n",
        "        query_to_dupl -> dict, query:id of its duplicate\n",
        "\n",
        "    \"\"\"\n",
        "    indexed = []\n",
        "    id_to_text = {}\n",
        "    query_to_dupl_id = {}\n",
        "    counter = 0\n",
        "\n",
        "    with open(corpus, 'r', encoding='utf-8') as f:\n",
        "        r = csv.reader(f)\n",
        "        for line in r:\n",
        "\n",
        "            if line[0] == '':\n",
        "                continue\n",
        "\n",
        "            _id, text, query, isduplicate = line\n",
        "            id_to_text[_id] = text\n",
        "\n",
        "            if isduplicate == '1':\n",
        "                query_to_dupl_id[query] = _id\n",
        "                \n",
        "            indexed.append(tokenize(text))\n",
        "                \n",
        "            counter += 1\n",
        "            if counter >= stop:\n",
        "                break\n",
        "    return indexed, id_to_text, query_to_dupl_id"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7JYKp1_y13yA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cleaned, id_to_text, query_to_dupl_id = get_data_elmo(corpus, stop=50000)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0R0elpH217oz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def crop_vec(vect, sent):\n",
        "    \"\"\"\n",
        "    Crops dummy values\n",
        "\n",
        "    :param vect: np.array, vector from ELMo\n",
        "    :param sent: list of str, tokenized sentence\n",
        "    :return: np.array\n",
        "\n",
        "    \"\"\"\n",
        "    cropped_vector = vect[:len(sent), :]\n",
        "    cropped_vector = np.mean(cropped_vector, axis=0)\n",
        "    return cropped_vector"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_QAegmS6199X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def indexing(cleaned, batcher, sentence_character_ids, elmo_sentence_input):\n",
        "    \"\"\" \n",
        "    Indexing corpus\n",
        "    :param cleaned: list if lists of str, tokenized documents from the corpus\n",
        "    :param batcher, sentence_character_ids, elmo_sentence_input: ELMo model\n",
        "\n",
        "    :return: matrix of document vectors\n",
        "    \"\"\"\n",
        "    with tf.Session() as sess:\n",
        "        # It is necessary to initialize variables once before running inference.\n",
        "        sess.run(tf.global_variables_initializer())\n",
        "        indexed = []\n",
        "        for i in range(200, len(cleaned)+1, 200):\n",
        "            sentences = cleaned[i-200 : i]\n",
        "            elmo_vectors = get_elmo_vectors(\n",
        "                sess, sentences, batcher, sentence_character_ids, elmo_sentence_input)\n",
        "\n",
        "            for vect, sent in zip(elmo_vectors, sentences):\n",
        "                cropped_vector = crop_vec(vect, sent)\n",
        "                indexed.append(cropped_vector)\n",
        "    return indexed"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GUfov_wh2AEe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "a480e007-6b1e-4b70-bb44-ec1822cbeb79"
      },
      "source": [
        "from time import time\n",
        "start = time()\n",
        "indexed = indexing(cleaned, batcher, sentence_character_ids, elmo_sentence_input)\n",
        "print('Затрачено секунд: ', time() - start)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sentences in this batch: 200\n",
            "Sentences in this batch: 200\n",
            "Sentences in this batch: 200\n",
            "Sentences in this batch: 200\n",
            "Sentences in this batch: 200\n",
            "Sentences in this batch: 200\n",
            "Sentences in this batch: 200\n",
            "Sentences in this batch: 200\n",
            "Sentences in this batch: 200\n",
            "Sentences in this batch: 200\n",
            "Sentences in this batch: 200\n",
            "Sentences in this batch: 200\n",
            "Sentences in this batch: 200\n",
            "Sentences in this batch: 200\n",
            "Sentences in this batch: 200\n",
            "Sentences in this batch: 200\n",
            "Sentences in this batch: 200\n",
            "/usr/local/lib/python3.6/dist-packages/numpy/core/fromnumeric.py:3118: RuntimeWarning: Mean of empty slice.\n",
            "  out=out, **kwargs)\n",
            "/usr/local/lib/python3.6/dist-packages/numpy/core/_methods.py:78: RuntimeWarning: invalid value encountered in true_divide\n",
            "  ret, rcount, out=ret, casting='unsafe', subok=False)\n",
            "Sentences in this batch: 200\n",
            "Sentences in this batch: 200\n",
            "Sentences in this batch: 200\n",
            "Sentences in this batch: 200\n",
            "Sentences in this batch: 200\n",
            "Sentences in this batch: 200\n",
            "Sentences in this batch: 200\n",
            "Sentences in this batch: 200\n",
            "Sentences in this batch: 200\n",
            "Sentences in this batch: 200\n",
            "Sentences in this batch: 200\n",
            "Sentences in this batch: 200\n",
            "Sentences in this batch: 200\n",
            "Sentences in this batch: 200\n",
            "Sentences in this batch: 200\n",
            "Sentences in this batch: 200\n",
            "Sentences in this batch: 200\n",
            "Sentences in this batch: 200\n",
            "Sentences in this batch: 200\n",
            "Sentences in this batch: 200\n",
            "Sentences in this batch: 200\n",
            "Sentences in this batch: 200\n",
            "Sentences in this batch: 200\n",
            "Sentences in this batch: 200\n",
            "Sentences in this batch: 200\n",
            "Sentences in this batch: 200\n",
            "Sentences in this batch: 200\n",
            "Sentences in this batch: 200\n",
            "Sentences in this batch: 200\n",
            "Sentences in this batch: 200\n",
            "Sentences in this batch: 200\n",
            "Sentences in this batch: 200\n",
            "Sentences in this batch: 200\n",
            "Sentences in this batch: 200\n",
            "Sentences in this batch: 200\n",
            "Sentences in this batch: 200\n",
            "Sentences in this batch: 200\n",
            "Sentences in this batch: 200\n",
            "Sentences in this batch: 200\n",
            "Sentences in this batch: 200\n",
            "Sentences in this batch: 200\n",
            "Sentences in this batch: 200\n",
            "Sentences in this batch: 200\n",
            "Sentences in this batch: 200\n",
            "Sentences in this batch: 200\n",
            "Sentences in this batch: 200\n",
            "Sentences in this batch: 200\n",
            "Sentences in this batch: 200\n",
            "Sentences in this batch: 200\n",
            "Sentences in this batch: 200\n",
            "Sentences in this batch: 200\n",
            "Sentences in this batch: 200\n",
            "Sentences in this batch: 200\n",
            "Sentences in this batch: 200\n",
            "Sentences in this batch: 200\n",
            "Sentences in this batch: 200\n",
            "Sentences in this batch: 200\n",
            "Sentences in this batch: 200\n",
            "Sentences in this batch: 200\n",
            "Sentences in this batch: 200\n",
            "Sentences in this batch: 200\n",
            "Sentences in this batch: 200\n",
            "Sentences in this batch: 200\n",
            "Sentences in this batch: 200\n",
            "Sentences in this batch: 200\n",
            "Sentences in this batch: 200\n",
            "Sentences in this batch: 200\n",
            "Sentences in this batch: 200\n",
            "Sentences in this batch: 200\n",
            "Sentences in this batch: 200\n",
            "Sentences in this batch: 200\n",
            "Sentences in this batch: 200\n",
            "Sentences in this batch: 200\n",
            "Sentences in this batch: 200\n",
            "Sentences in this batch: 200\n",
            "Sentences in this batch: 200\n",
            "Sentences in this batch: 200\n",
            "Sentences in this batch: 200\n",
            "Sentences in this batch: 200\n",
            "Sentences in this batch: 200\n",
            "Sentences in this batch: 200\n",
            "Sentences in this batch: 200\n",
            "Sentences in this batch: 200\n",
            "Sentences in this batch: 200\n",
            "Sentences in this batch: 200\n",
            "Sentences in this batch: 200\n",
            "Sentences in this batch: 200\n",
            "Sentences in this batch: 200\n",
            "Sentences in this batch: 200\n",
            "Sentences in this batch: 200\n",
            "Sentences in this batch: 200\n",
            "Sentences in this batch: 200\n",
            "Sentences in this batch: 200\n",
            "Sentences in this batch: 200\n",
            "Sentences in this batch: 200\n",
            "Sentences in this batch: 200\n",
            "Sentences in this batch: 200\n",
            "Sentences in this batch: 200\n",
            "Sentences in this batch: 200\n",
            "Sentences in this batch: 200\n",
            "Sentences in this batch: 200\n",
            "Sentences in this batch: 200\n",
            "Sentences in this batch: 200\n",
            "Sentences in this batch: 200\n",
            "Sentences in this batch: 200\n",
            "Sentences in this batch: 200\n",
            "Sentences in this batch: 200\n",
            "Sentences in this batch: 200\n",
            "Sentences in this batch: 200\n",
            "Sentences in this batch: 200\n",
            "Sentences in this batch: 200\n",
            "Sentences in this batch: 200\n",
            "Sentences in this batch: 200\n",
            "Sentences in this batch: 200\n",
            "Sentences in this batch: 200\n",
            "Sentences in this batch: 200\n",
            "Sentences in this batch: 200\n",
            "Sentences in this batch: 200\n",
            "Sentences in this batch: 200\n",
            "Sentences in this batch: 200\n",
            "Sentences in this batch: 200\n",
            "Sentences in this batch: 200\n",
            "Sentences in this batch: 200\n",
            "Sentences in this batch: 200\n",
            "Sentences in this batch: 200\n",
            "Sentences in this batch: 200\n",
            "Sentences in this batch: 200\n",
            "Sentences in this batch: 200\n",
            "Sentences in this batch: 200\n",
            "Sentences in this batch: 200\n",
            "Sentences in this batch: 200\n",
            "Sentences in this batch: 200\n",
            "Sentences in this batch: 200\n",
            "Sentences in this batch: 200\n",
            "Sentences in this batch: 200\n",
            "Sentences in this batch: 200\n",
            "Sentences in this batch: 200\n",
            "Sentences in this batch: 200\n",
            "Sentences in this batch: 200\n",
            "Sentences in this batch: 200\n",
            "Sentences in this batch: 200\n",
            "Sentences in this batch: 200\n",
            "Sentences in this batch: 200\n",
            "Sentences in this batch: 200\n",
            "Sentences in this batch: 200\n",
            "Sentences in this batch: 200\n",
            "Sentences in this batch: 200\n",
            "Sentences in this batch: 200\n",
            "Sentences in this batch: 200\n",
            "Sentences in this batch: 200\n",
            "Sentences in this batch: 200\n",
            "Sentences in this batch: 200\n",
            "Sentences in this batch: 200\n",
            "Sentences in this batch: 200\n",
            "Sentences in this batch: 200\n",
            "Sentences in this batch: 200\n",
            "Sentences in this batch: 200\n",
            "Sentences in this batch: 200\n",
            "Sentences in this batch: 200\n",
            "Sentences in this batch: 200\n",
            "Sentences in this batch: 200\n",
            "Sentences in this batch: 200\n",
            "Sentences in this batch: 200\n",
            "Sentences in this batch: 200\n",
            "Sentences in this batch: 200\n",
            "Sentences in this batch: 200\n",
            "Sentences in this batch: 200\n",
            "Sentences in this batch: 200\n",
            "Sentences in this batch: 200\n",
            "Sentences in this batch: 200\n",
            "Sentences in this batch: 200\n",
            "Sentences in this batch: 200\n",
            "Sentences in this batch: 200\n",
            "Sentences in this batch: 200\n",
            "Sentences in this batch: 200\n",
            "Sentences in this batch: 200\n",
            "Sentences in this batch: 200\n",
            "Sentences in this batch: 200\n",
            "Sentences in this batch: 200\n",
            "Sentences in this batch: 200\n",
            "Sentences in this batch: 200\n",
            "Sentences in this batch: 200\n",
            "Sentences in this batch: 200\n",
            "Sentences in this batch: 200\n",
            "Sentences in this batch: 200\n",
            "Sentences in this batch: 200\n",
            "Sentences in this batch: 200\n",
            "Sentences in this batch: 200\n",
            "Sentences in this batch: 200\n",
            "Sentences in this batch: 200\n",
            "Sentences in this batch: 200\n",
            "Sentences in this batch: 200\n",
            "Sentences in this batch: 200\n",
            "Sentences in this batch: 200\n",
            "Sentences in this batch: 200\n",
            "Sentences in this batch: 200\n",
            "Sentences in this batch: 200\n",
            "Sentences in this batch: 200\n",
            "Sentences in this batch: 200\n",
            "Sentences in this batch: 200\n",
            "Sentences in this batch: 200\n",
            "Sentences in this batch: 200\n",
            "Sentences in this batch: 200\n",
            "Sentences in this batch: 200\n",
            "Sentences in this batch: 200\n",
            "Sentences in this batch: 200\n",
            "Sentences in this batch: 200\n",
            "Sentences in this batch: 200\n",
            "Sentences in this batch: 200\n",
            "Sentences in this batch: 200\n",
            "Sentences in this batch: 200\n",
            "Sentences in this batch: 200\n",
            "Sentences in this batch: 200\n",
            "Sentences in this batch: 200\n",
            "Sentences in this batch: 200\n",
            "Sentences in this batch: 200\n",
            "Sentences in this batch: 200\n",
            "Sentences in this batch: 200\n",
            "Sentences in this batch: 200\n",
            "Sentences in this batch: 200\n",
            "Sentences in this batch: 200\n",
            "Sentences in this batch: 200\n",
            "Sentences in this batch: 200\n",
            "Sentences in this batch: 200\n",
            "Sentences in this batch: 200\n",
            "Sentences in this batch: 200\n",
            "Sentences in this batch: 200\n",
            "Sentences in this batch: 200\n",
            "Sentences in this batch: 200\n",
            "Sentences in this batch: 200\n",
            "Sentences in this batch: 200\n",
            "Sentences in this batch: 200\n",
            "Sentences in this batch: 200\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Затрачено секунд:  3644.9178235530853\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sChBrl5Z2CQM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pickle\n",
        "\n",
        "with open('Indexed_ELMO.pickle', 'wb') as f:\n",
        "    pickle.dump((indexed, id_to_text, query_to_dupl_id), f)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9plfFxOcLrgn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def cos_sim(v1, v2):\n",
        "    \"\"\"Counts cosine similarity between two vectors\"\"\"\n",
        "    return np.inner(v1, v2) / (np.linalg.norm(v1) * np.linalg.norm(v2))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M_N05lWoMBQ7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pickle\n",
        "\n",
        "with open('Indexed_ELMO.pickle', 'rb') as f:\n",
        "    indexed, id_to_text, query_to_dupl_id = pickle.load(f)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k2OkpxZ0MDRA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def prepare_query(query, batcher, sentence_character_ids, elmo_sentence_input):\n",
        "    \"\"\" \n",
        "    Gets vector of query\n",
        "\n",
        "    :param query: str\n",
        "    :param batcher, sentence_character_ids, elmo_sentence_input: ELMo model\n",
        "    \n",
        "    :return: vector of query\n",
        "    \"\"\"\n",
        "    q = [tokenize(query)]\n",
        "    with tf.Session() as sess:\n",
        "        sess.run(tf.global_variables_initializer())\n",
        "        vector = crop_vec(get_elmo_vectors(sess, q, batcher,\n",
        "                                           sentence_character_ids,\n",
        "                                           elmo_sentence_input)[0], q[0])\n",
        "    return vector"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r9OoOsSvMFi1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def search_tool_elmo(query, batcher, sentence_character_ids,\n",
        "                     elmo_sentence_input, indexed):\n",
        "    \"\"\"\n",
        "    Search query in corpus\n",
        "\n",
        "    :param: query: str\n",
        "    :param batcher, sentence_character_ids, elmo_sentence_input: ELMo model\n",
        "    :param indexed: np.array, matrix of indexed corpus\n",
        "\n",
        "    :return: list, sorted results\n",
        "    \"\"\"\n",
        "    q = prepare_query(query, batcher, sentence_character_ids, \n",
        "                      elmo_sentence_input)\n",
        "\n",
        "    result = {}\n",
        "    for i, doc_vector in enumerate(indexed):\n",
        "        score =  cos_sim(q, doc_vector)\n",
        "        if type(score) is np.float32:\n",
        "            result[i] = score\n",
        "    \n",
        "    return sorted(result.items(), key=lambda x: x[1], reverse=True)\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nmNRNz7vMLVA",
        "colab_type": "text"
      },
      "source": [
        "# Качество поиска"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wtKLRQS1MHgb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_score_elmo(indexed, query_to_dupl_id, batcher, sentence_character_ids, \n",
        "                   elmo_sentence_input, test=100):\n",
        "    \"\"\"\n",
        "    Counts the quality of the search (from 0 to 1.0)\n",
        "    \"\"\"\n",
        "    test_query = list(query_to_dupl_id.keys())\n",
        "\n",
        "    if test != 0:\n",
        "        test_query =  test_query[:test]\n",
        "    \n",
        "    test_len = len(test_query)\n",
        "    counter = 0\n",
        "\n",
        "    for q in test_query:\n",
        "        dupl_id = int(query_to_dupl_id[q])\n",
        "\n",
        "        results = search_tool_elmo(q, batcher, sentence_character_ids,\n",
        "                                   elmo_sentence_input, indexed)[:5]\n",
        "        text_ids = [result[0] for result in results]\n",
        "\n",
        "        if dupl_id in text_ids:\n",
        "            counter += 1\n",
        "    \n",
        "    return counter / test_len"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "biKE6o63MSZD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "start = time()\n",
        "print(get_score_elmo(indexed,query_to_dupl_id, batcher, sentence_character_ids, \n",
        "                   elmo_sentence_input))\n",
        "print('Затрачено времени', time() - start)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}