{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Лекция 2  BM5    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Функция ранжирования bm25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для обратного индекса есть общепринятая формула для ранжирования *Okapi best match 25* ([Okapi BM25](https://ru.wikipedia.org/wiki/Okapi_BM25)).    \n",
    "Пусть дан запрос $Q$, содержащий слова  $q_1, ... , q_n$, тогда функция BM25 даёт следующую оценку релевантности документа $D$ запросу $Q$:\n",
    "\n",
    "$$ score(D, Q) = \\sum_{i}^{n} \\text{IDF}(q_i)*\\frac{TF(q_i,D)*(k+1)}{TF(q_i,D)+k(1-b+b\\frac{l(d)}{avgdl})} $$ \n",
    "где   \n",
    ">$TF(q_i,D)$ - частота слова $q_i$ в документе $D$      \n",
    "$l(d)$ - длина документа (количество слов в нём)   \n",
    "*avgdl* — средняя длина документа в коллекции    \n",
    "$k$ и $b$ — свободные коэффициенты, обычно их выбирают как $k$=2.0 и $b$=0.75   \n",
    "$$$$\n",
    "$\\text{IDF}(q_i)$ - это модернизированная версия IDF: \n",
    "$$\\text{IDF}(q_i) = \\log\\frac{N-n(q_i)+0.5}{n(q_i)+0.5},$$\n",
    ">> где $N$ - общее количество документов в коллекции   \n",
    "$n(q_i)$ — количество документов, содержащих $q_i$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import nltk\n",
    "import re\n",
    "import csv\n",
    "import numpy\n",
    "import time\n",
    "from math import log\n",
    "import pymorphy2\n",
    "morph = pymorphy2.MorphAnalyzer()\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "tokenizer = RegexpTokenizer(r'\\w+')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/victoriaregina/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download(\"stopwords\")\n",
    "from nltk.corpus import stopwords\n",
    "russian_stopwords = stopwords.words(\"russian\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = []\n",
    "queries = []\n",
    "length = []\n",
    "ids = []\n",
    "dic = {}\n",
    "texts = {}\n",
    "rel = {}\n",
    "with open('/Users/victoriaregina/Downloads/quora_question_pairs_rus.csv', 'r') as file:\n",
    "    csv_reader = csv.reader(file, delimiter=',')\n",
    "    line_count = 0\n",
    "    for row in csv_reader:\n",
    "        normal_forms_docs = []\n",
    "        normal_forms_queries = []\n",
    "        if line_count == 0:\n",
    "            line_count += 1\n",
    "        else:\n",
    "            if line_count<=1000:\n",
    "                for t in tokenizer.tokenize(row[2]):\n",
    "                    t = morph.parse(t)[0]\n",
    "                    if t.normal_form not in russian_stopwords and t.normal_form != 'это' and not re.match(r'[0-9A-Za-z]', t.normal_form):\n",
    "                        normal_forms_docs.append(t.normal_form)\n",
    "                        dic[row[0]] = len(normal_forms_docs)\n",
    "                        st_doc = ' '.join(normal_forms_docs)\n",
    "                        texts[row[0]] = st_doc\n",
    "                corpus.append(st_doc)\n",
    "                ids.append(row[0])\n",
    "                length.append(len(normal_forms_docs))\n",
    "                for t in tokenizer.tokenize(row[1]):\n",
    "                    t = morph.parse(t)[0]\n",
    "                    if t.normal_form not in russian_stopwords and t.normal_form != 'это' and not re.match(r'[0-9A-Za-z]', t.normal_form):\n",
    "                        normal_forms_queries.append(t.normal_form)\n",
    "                        st_query = ' '.join(normal_forms_queries)\n",
    "                rel[(st_query, row[0])] = row[3]\n",
    "                queries.append(st_query)        \n",
    "            else:\n",
    "                break\n",
    "            line_count += 1\n",
    "    avlen = numpy.mean(length) #средняя длина документа\n",
    "    N = line_count - 1 #всего документов в коллекции"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vec = CountVectorizer()\n",
    "X = vec.fit_transform(corpus)\n",
    "\n",
    "df = pd.DataFrame(X.toarray(), columns=vec.get_feature_names(), index=ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df['sum'] = df.sum(axis=1) \n",
    "tf_table = df.div(df['sum'], axis=0) \n",
    "tf_table = tf_table.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#так считаем кол-во документов с этим словом\n",
    "d = df.isin([0])\n",
    "nqi = {}\n",
    "for c in vec.get_feature_names():\n",
    "    s = N - sum(d[c]) #кол-во документов с этим словом\n",
    "    nqi[c] = s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __Задача 1__:    \n",
    "Напишите два поисковика на *BM25*. Один через подсчет метрики по формуле для каждой пары слово-документ, второй через умножение матрицы на вектор. \n",
    "\n",
    "Сравните время работы поиска на 100к запросах. В качестве корпуса возьмем \n",
    "[Quora question pairs](https://www.kaggle.com/loopdigga/quora-question-pairs-russian)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Подсчет метрики по формуле для каждой пары слово-документ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bm25(i, q, k, b, N, avlen, nqi) -> float:\n",
    "    try:\n",
    "        A = log((N - nqi[q] + 0.5)/(nqi[q] + 0.5))\n",
    "        B = tf_table.at[str(i), q] * (k+1)/(tf_table.at[str(i), q] + k*(1 - b + b*(N/avlen)))\n",
    "    except KeyError:\n",
    "        n = 0\n",
    "        A = log((N - n + 0.5)/(n + 0.5))\n",
    "        B = 0\n",
    "    score = A * B\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Затраченное время для подсчета BM25 81.8839 s\n"
     ]
    }
   ],
   "source": [
    "k = 2.0\n",
    "b = 0.75\n",
    "start_time = time.clock()\n",
    "for query in queries:\n",
    "    bm25_dic = {}\n",
    "    for i in ids:\n",
    "        score = []\n",
    "        for q in query.split():\n",
    "            sp = bm25(i, q, k, b, N, avlen, nqi)\n",
    "            score.append(sp)\n",
    "    s = numpy.sum(score)\n",
    "print(\"Затраченное время для подсчета BM25\", \"{:g} s\".format(time.clock() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Подсчет метрики через умножение матрицы на вектор"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = []\n",
    "queries = []\n",
    "length = []\n",
    "ids = []\n",
    "dic = {}\n",
    "texts = {}\n",
    "rel = {}\n",
    "with open('/Users/victoriaregina/Downloads/quora_question_pairs_rus.csv', 'r') as file:\n",
    "    csv_reader = csv.reader(file, delimiter=',')\n",
    "    line_count = 0\n",
    "    for row in csv_reader:\n",
    "        normal_forms_docs = []\n",
    "        normal_forms_queries = []\n",
    "        if line_count == 0:\n",
    "            line_count += 1\n",
    "        else:\n",
    "            if line_count<=100:\n",
    "                for t in tokenizer.tokenize(row[2]):\n",
    "                    t = morph.parse(t)[0]\n",
    "                    if t.normal_form not in russian_stopwords and t.normal_form != 'это' and not re.match(r'[0-9A-Za-z]', t.normal_form):\n",
    "                        normal_forms_docs.append(t.normal_form)\n",
    "                        dic[row[0]] = len(normal_forms_docs)\n",
    "                        st_doc = ' '.join(normal_forms_docs)\n",
    "                        texts[row[0]] = st_doc\n",
    "                corpus.append(st_doc)\n",
    "                ids.append(row[0])\n",
    "                length.append(len(normal_forms_docs))\n",
    "                for t in tokenizer.tokenize(row[1]):\n",
    "                    t = morph.parse(t)[0]\n",
    "                    if t.normal_form not in russian_stopwords and t.normal_form != 'это' and not re.match(r'[0-9A-Za-z]', t.normal_form):\n",
    "                        normal_forms_queries.append(t.normal_form)\n",
    "                        st_query = ' '.join(normal_forms_queries)\n",
    "                rel[(st_query, row[0])] = row[3]\n",
    "                queries.append(st_query)        \n",
    "            else:\n",
    "                break\n",
    "            line_count += 1\n",
    "    avlen = numpy.mean(length) #средняя длина документа\n",
    "    N = line_count - 1 #всего документов в коллекции"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vec = CountVectorizer()\n",
    "X = vec.fit_transform(corpus)\n",
    "\n",
    "df = pd.DataFrame(X.toarray(), columns=vec.get_feature_names(), index=ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bm25(i, q, k, b, N, avlen, nqi) -> float:\n",
    "    try:\n",
    "        A = log((N - nqi[q] + 0.5)/(nqi[q] + 0.5))\n",
    "        B = tf_table.at[str(i), q] * (k+1)/(tf_table.at[str(i), q] + k*(1 - b + b*(N/avlen)))\n",
    "    except KeyError:\n",
    "        n = 0\n",
    "        A = log((N - n + 0.5)/(n + 0.5))\n",
    "        B = 0\n",
    "    score = A * B\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['sum'] = df.sum(axis=1) \n",
    "tf_table = df.div(df['sum'], axis=0) \n",
    "tf_table = tf_table.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#так считаем кол-во документов с этим словом\n",
    "d = df.isin([0])\n",
    "nqi = {}\n",
    "for c in vec.get_feature_names():\n",
    "    s = N - sum(d[c]) #кол-во документов с этим словом\n",
    "    nqi[c] = s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Затраченное время для подсчета BM25 0.63531 s\n"
     ]
    }
   ],
   "source": [
    "k = 2.0\n",
    "b = 0.75\n",
    "matrix = []\n",
    "start_time = time.clock()\n",
    "for query in queries:\n",
    "    bm25_dic = {}\n",
    "    for i in ids:\n",
    "        mat = {}\n",
    "        score = []\n",
    "        for q in query.split():\n",
    "            sp = bm25(i, q, k, b, N, avlen, nqi)\n",
    "            mat[q] = sp\n",
    "        matrix.append(mat)\n",
    "\n",
    "print(\"Затраченное время для подсчета BM25\", \"{:g} s\".format(time.clock() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = pd.DataFrame(matrix) #создаем матрицу со значением BM25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "bm25_mat = df3.fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Задание 2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выведите 10 первых результатов и их близость по метрике BM25 по запросу **рождественские каникулы** на нашем корпусе  Quora question pairs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in tokenizer.tokenize('рождественские каникулы'):\n",
    "    t = morph.parse(t)[0]\n",
    "    if t.normal_form not in russian_stopwords and t.normal_form != 'это' and not re.match(r'[0-9A-Za-z]', t.normal_form):\n",
    "        normal_forms_queries.append(t.normal_form)\n",
    "        st_query = ' '.join(normal_forms_queries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Вот релевантный документ: мочь преобразовать необработанный файл фотография; его близость по метрике BM25 равна 0.0\n"
     ]
    }
   ],
   "source": [
    "k = 2.0\n",
    "b = 0.75\n",
    "accuracy = 0\n",
    "bm25_dic = {}\n",
    "for i in ids:\n",
    "    score = []\n",
    "    for q in st_query.split():\n",
    "        sp = bm25(i, q, k, b, N, avlen, nqi)\n",
    "        score.append(sp)\n",
    "    s = numpy.sum(score)\n",
    "    bm25_dic[s] = (query, i)\n",
    "m = list(bm25_dic.keys())\n",
    "m = sorted(m)\n",
    "for p in m[-10:]: #берем топ 10 документов по метрике bm25\n",
    "    t = bm25_dic[p]\n",
    "    print('Вот релевантный документ: '+ t[0] +'; его близость по метрике BM25 равна', p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __Задача 3__:    \n",
    "\n",
    "Посчитайте точность поиска при \n",
    "1. BM25, b=0.75 \n",
    "2. BM15, b=0 \n",
    "3. BM11, b=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def acc(a, k, metrika):\n",
    "    accuracy = 0\n",
    "    for query in queries:\n",
    "        bm25_dic = {}\n",
    "        for i in ids:\n",
    "            score = []\n",
    "            for q in query.split():\n",
    "                sp = bm25(i, q, k, metrika, N, avlen, nqi)\n",
    "                score.append(sp)\n",
    "            s = numpy.sum(score)\n",
    "            bm25_dic[s] = (query, i)\n",
    "        m = list(bm25_dic.keys())\n",
    "        m = sorted(m)\n",
    "        for p in m[-5:]: #берем топ 5 документов по метрике bm25\n",
    "            t = bm25_dic[p]\n",
    "            try:\n",
    "                if rel[t] == str(1) and p > 0:\n",
    "                    accuracy += 1\n",
    "            except KeyError:\n",
    "                pass\n",
    "    gen_accuracy = accuracy/N\n",
    "    a[metrika] = gen_accuracy\n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = {}\n",
    "k = 2.0\n",
    "for i in [0.75, 0, 1]:\n",
    "    acc(a, k, i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Точность поиска при b=0.75 равна 0.319\n",
      "Точность поиска при b=0 равна 0.319\n",
      "Точность поиска при b=1 равна 0.319\n"
     ]
    }
   ],
   "source": [
    "print('Точность поиска при b=0.75 равна', a[0.75])\n",
    "print('Точность поиска при b=0 равна', a[0])\n",
    "print('Точность поиска при b=1 равна', a[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
